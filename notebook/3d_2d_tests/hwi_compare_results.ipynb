{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- testFile-100-2D ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "prev CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "new CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "prev CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "\n",
      "--- data_0.528_3.8_000160 ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 2653 is not the same as expected 3698\n",
      "prev STAT_e failed - 3649 is not the same as expected 3698\n",
      "\n",
      "--- morphology_resize_0.25x ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 412 is not the same as expected 613\n",
      "prev STAT_e failed - 596 is not the same as expected 613\n",
      "new CT_n_D_adj_An failed - 48 is not the same as expected 49\n",
      "prev CT_n_D_adj_An failed - 48 is not the same as expected 49\n",
      "new CT_n_A_adj_Ca failed - 29 is not the same as expected 30\n",
      "prev CT_n_A_adj_Ca failed - 29 is not the same as expected 30\n",
      "\n",
      "--- morphology_resize_4.0x ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 8996 is not the same as expected 9888\n",
      "prev STAT_e failed - 9872 is not the same as expected 9888\n",
      "new CT_n_D_adj_An failed - 760 is not the same as expected 761\n",
      "prev CT_n_D_adj_An failed - 760 is not the same as expected 761\n",
      "new CT_n_A_adj_Ca failed - 436 is not the same as expected 437\n",
      "prev CT_n_A_adj_Ca failed - 436 is not the same as expected 437\n",
      "\n",
      "--- data_0.615_4.0_000160 ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 2390 is not the same as expected 3523\n",
      "prev STAT_e failed - 3372 is not the same as expected 3523\n",
      "\n",
      "--- testFile-10-2D ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "prev CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "new CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "prev CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "\n",
      "--- morphology_resize_2.0x ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 4342 is not the same as expected 4944\n",
      "prev STAT_e failed - 4928 is not the same as expected 4944\n",
      "new CT_n_D_adj_An failed - 380 is not the same as expected 381\n",
      "prev CT_n_D_adj_An failed - 380 is not the same as expected 381\n",
      "new CT_n_A_adj_Ca failed - 218 is not the same as expected 219\n",
      "prev CT_n_A_adj_Ca failed - 218 is not the same as expected 219\n",
      "\n",
      "--- data_0.5_2.6_000160 ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 1490 is not the same as expected 2022\n",
      "prev STAT_e failed - 2018 is not the same as expected 2022\n",
      "new CT_f_conn_A_Ca failed - 0.724838 is not the same as expected 0.724837\n",
      "prev CT_f_conn_A_Ca failed - 0.724838 is not the same as expected 0.724837\n",
      "\n",
      "--- data_5x4x3 ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 36 is not the same as expected 48\n",
      "prev STAT_e failed - 36 is not the same as expected 48\n",
      "new CT_n_D_adj_An failed - 12 is not the same as expected 13\n",
      "prev CT_n_D_adj_An failed - 12 is not the same as expected 13\n",
      "new CT_n_A_adj_Ca failed - 8 is not the same as expected 9\n",
      "prev CT_n_A_adj_Ca failed - 8 is not the same as expected 9\n",
      "\n",
      "--- testFile-50-2D ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "prev CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "new CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "prev CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "\n",
      "--- testFile-1000-2D ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "prev CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "new CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "prev CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "\n",
      "--- testFile-500-2D ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "prev CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "new CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "prev CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "\n",
      "--- morphology_resize_1.0x ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 2015 is not the same as expected 2472\n",
      "prev STAT_e failed - 2456 is not the same as expected 2472\n",
      "new CT_n_D_adj_An failed - 190 is not the same as expected 191\n",
      "prev CT_n_D_adj_An failed - 190 is not the same as expected 191\n",
      "new CT_n_A_adj_Ca failed - 109 is not the same as expected 110\n",
      "prev CT_n_A_adj_Ca failed - 109 is not the same as expected 110\n",
      "\n",
      "--- data_4x3x2 ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 10 is not the same as expected 24\n",
      "prev STAT_e failed - 12 is not the same as expected 24\n",
      "new CT_n_D_adj_An failed - 6 is not the same as expected 7\n",
      "prev CT_n_D_adj_An failed - 6 is not the same as expected 7\n",
      "new CT_n_A_adj_Ca failed - 6 is not the same as expected 7\n",
      "prev CT_n_A_adj_Ca failed - 6 is not the same as expected 7\n",
      "\n",
      "--- morphology_resize_0.5x ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 843 is not the same as expected 1226\n",
      "prev STAT_e failed - 1208 is not the same as expected 1226\n",
      "new CT_n_D_adj_An failed - 94 is not the same as expected 95\n",
      "prev CT_n_D_adj_An failed - 94 is not the same as expected 95\n",
      "new CT_n_A_adj_Ca failed - 54 is not the same as expected 55\n",
      "prev CT_n_A_adj_Ca failed - 54 is not the same as expected 55\n",
      "\n",
      "--- data_4x3x1 ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "new STAT_e failed - 5 is not the same as expected 8\n",
      "prev STAT_e failed - 6 is not the same as expected 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################  readme  #####################################\n",
    "# comparing the descriptors between new version and old version\n",
    "# you can change targetFileName variable(line 25) to run the code with different file\n",
    "# if the descriptors are the same, then you can see OK and value\n",
    "#######################################################################################\n",
    "\n",
    "import hwi_igraph_testing_main as ig\n",
    "import igraph_testing_main as ig2\n",
    "import importlib\n",
    "import descriptors as ds\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tracemalloc\n",
    "\n",
    "importlib.reload(ig)\n",
    "importlib.reload(ig2)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_path = f\"{current_dir}/graspi_igraph/data/\"\n",
    "descriptors_path = f\"{current_dir}/graspi_igraph/p1descriptors/\"\n",
    "test_files = [os.path.splitext(file)[0] for file in os.listdir(data_path)]\n",
    "epsilon = 1e-5\n",
    "\n",
    "targetFileName = '4x3x2'    \n",
    "loop_cnt = 1\n",
    "\n",
    "def run_test(lib, test_file):\n",
    "    total_graph_time = 0\n",
    "    tracemalloc.start()\n",
    "    graph_start = time.time()\n",
    "    g, *_ = lib.generateGraph(data_path + test_file + \".txt\")\n",
    "    _stats = tracemalloc.get_traced_memory()\n",
    "    graph_end = time.time()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    graph_mem = _stats[1] - _stats[0]\n",
    "    stats = ds.desciptors(g)\n",
    "    graph_time = graph_end - graph_start\n",
    "    return stats, graph_time, graph_mem\n",
    "\n",
    "# Run and compare for both ig and ig2\n",
    "def test(singlefileonly):\n",
    "    failonly = True\n",
    "    for test_file in test_files:\n",
    "        if singlefileonly == True and targetFileName not in test_file:\n",
    "                continue\n",
    "\n",
    "        print(f\"--- {test_file} ---\")\n",
    "\n",
    "        # Run for ig\n",
    "        stats_ig, time_ig, mem_ig = run_test(ig, test_file)\n",
    "\n",
    "        # Run for ig2\n",
    "        stats_ig2, time_ig2, mem_ig2 = run_test(ig2, test_file)\n",
    "\n",
    "        print(\"\\n[Descriptor Comparison]\")\n",
    "\n",
    "        with open(descriptors_path + \"p1descriptors.\" + test_file + \".log\") as f:\n",
    "            for line in f:\n",
    "                stat = line.strip().split(\" \")\n",
    "                try:\n",
    "                    # if stats.get(stat[0], -1) == int(stat[1]):\n",
    "                    if failonly == False and abs(stats_ig.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                        print(f\"new {stat[0]} passed\")\n",
    "                    elif failonly == True and stats_ig.get(stat[0], -1) != -1 and stats_ig.get(stat[0], -1) != int(stat[1]):\n",
    "                        print(f\"new {stat[0]} failed - {stats_ig.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "\n",
    "                    if failonly == False and abs(stats_ig2.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                        print(f\"prev {stat[0]} passed\")\n",
    "                    elif failonly == True and stats_ig2.get(stat[0], -1) != -1 and stats_ig2.get(stat[0], -1) != int(stat[1]):\n",
    "                        print(f\"prev {stat[0]} failed - {stats_ig2.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "                    # print(\"-----------------\")\n",
    "\n",
    "                except ValueError:\n",
    "                    if failonly == False and abs(stats_ig.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                        print(f\"new {stat[0]} passed\")\n",
    "                    elif stats_ig.get(stat[0], -1) != -1 and stats_ig.get(stat[0], -1) != float(stat[1]):\n",
    "                        print(f\"new {stat[0]} failed - {stats_ig.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "\n",
    "                    if failonly == False and abs(stats_ig2.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                        print(f\"prev {stat[0]} passed\")\n",
    "                    elif stats_ig2.get(stat[0], -1) != -1 and stats_ig2.get(stat[0], -1) != float(stat[1]):\n",
    "                        print(f\"prev {stat[0]} failed - {stats_ig.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "                    # print(\"-----------------\")\n",
    "\n",
    "\n",
    "        # Time and memory comparison\n",
    "        # print(\"\\n[Performance Comparison]\")\n",
    "        # print(f\"Graph Generation Time - new: {time_ig:.6f}s, prev: {time_ig2:.6f}s\")\n",
    "        # print(f\"Graph Memory Usage     - new: {mem_ig} bytes, prev: {mem_ig2} bytes\")\n",
    "        # print(f\"Descriptor Time        - new: {stats_ig['time']:.6f}s, prev: {stats_ig2['time']:.6f}s\")\n",
    "        # print(f\"Descriptor Memory      - new: {stats_ig['mem']} bytes, prev: {stats_ig2['mem']} bytes\")\n",
    "        print()\n",
    "\n",
    "test(singlefileonly=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## individual code : new_version\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphology_resize_0.25x Results\n",
      "STAT_n passed\n",
      "STAT_e failed - 561 is not the same as expected 613\n",
      "STAT_n_D passed\n",
      "STAT_n_A passed\n",
      "STAT_CC_D passed\n",
      "STAT_CC_A passed\n",
      "STAT_CC_D_An passed\n",
      "STAT_CC_A_Ca passed\n",
      "ABS_f_D passed\n",
      "CT_f_conn_D_An passed\n",
      "CT_f_conn_A_Ca passed\n",
      "CT_n_D_adj_An failed - 48 is not the same as expected 49\n",
      "CT_n_A_adj_Ca failed - 29 is not the same as expected 30\n",
      "Total time to calculate graph: 2.1280808448791504 second(s)\n",
      "Total time to calculate descriptors: 0.36905598640441895 second(s)\n",
      "Peak memory usage for graph generation: 4317680 bytes\n",
      "Peak memory usage for descriptor calculation: 29959 bytes\n",
      "{'STAT_n': 3780, 'STAT_e': 561, 'STAT_n_D': 2035, 'STAT_n_A': 1745, 'STAT_CC_D': 7, 'STAT_CC_A': 1, 'STAT_CC_D_An': 3, 'STAT_CC_A_Ca': 1, 'ABS_f_D': 0.53836, 'CT_f_conn_D_An': 0.287961, 'CT_f_conn_A_Ca': 1.0, 'CT_n_D_adj_An': 48, 'CT_n_A_adj_Ca': 29, 'time': 0.36905598640441895, 'mem': 29959}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hwi_igraph_testing_main as ig\n",
    "import importlib\n",
    "import descriptors as ds\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tracemalloc\n",
    "\n",
    "importlib.reload(ig)  \n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_path = f\"{current_dir}/graspi_igraph/data/\"\n",
    "descriptors_path = f\"{current_dir}/graspi_igraph/p1descriptors/\"\n",
    "test_files = [os.path.splitext(file)[0] for file in os.listdir(data_path)]\n",
    "epsilon=1e-5\n",
    "\n",
    "times = []\n",
    "mems = []\n",
    "time_mem_stats = {}\n",
    "\n",
    "targetFileName = '0.25'\n",
    "loop_cnt = 1\n",
    "\n",
    "    \n",
    "for test_file in test_files:\n",
    "    if targetFileName not in test_file:\n",
    "        continue\n",
    "\n",
    "    import time\n",
    "    total_graph_time = 0\n",
    "    for i in range(loop_cnt):\n",
    "\n",
    "        # g = ig.generateGraph(data_path + test_file + \".txt\")\n",
    "        tracemalloc.start()\n",
    "        graph_start = time.time()\n",
    "        g,is_2D, black_vertices, white_vertices, black_green, black_interface_red, white_interface_blue, dim, interface_edge_comp_paths, shortest_path_to_red, shortest_path_to_blue, CT_n_D_adj_An, CT_n_A_adj_Ca= ig.generateGraph(data_path + test_file + \".txt\")\n",
    "        _stats = tracemalloc.get_traced_memory()\n",
    "        graph_end = time.time()     \n",
    "        tracemalloc.stop()\n",
    "        graph_mem = _stats[1]-_stats[0]  \n",
    "        stats = ds.desciptors(g)\n",
    "        total_graph_time += graph_end - graph_start\n",
    "        #ig.visual2D(g, 'graph')\n",
    "\n",
    "    print(f\"{test_file} Results\")\n",
    "\n",
    "    with open(descriptors_path + \"p1descriptors.\" + test_file + \".log\") as f:\n",
    "        for line in f:\n",
    "            stat = line.strip().split(\" \")\n",
    "            try:\n",
    "                # if stats.get(stat[0], -1) == int(stat[1]):\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != int(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "            except ValueError:\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != float(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "    descriptor_time = stats[\"time\"]\n",
    "    descriptor_mem = stats[\"mem\"]\n",
    "\n",
    "    times.append(descriptor_time)\n",
    "    mems.append(descriptor_mem)\n",
    "\n",
    "    graph_time = total_graph_time/loop_cnt\n",
    "    print(f\"Total time to calculate graph: {graph_time} second(s)\")\n",
    "    print(f\"Total time to calculate descriptors: {descriptor_time} second(s)\")\n",
    "    print(f\"Peak memory usage for graph generation: {graph_mem} bytes\")\n",
    "    print(f\"Peak memory usage for descriptor calculation: {descriptor_mem} bytes\")\n",
    "    print(stats)\n",
    "    print(\"\")\n",
    "    time_mem_stats[test_file] = {\"graph_time\": graph_time, \"descriptor_time\": descriptor_time,  \"graph_mem\":graph_mem, \"descriptor_mem\": descriptor_mem}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## individual code : previous version\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphology_resize_0.25x Results\n",
      "STAT_n passed\n",
      "STAT_e failed - 596 is not the same as expected 613\n",
      "STAT_n_D passed\n",
      "STAT_n_A passed\n",
      "STAT_CC_D passed\n",
      "STAT_CC_A passed\n",
      "STAT_CC_D_An passed\n",
      "STAT_CC_A_Ca passed\n",
      "ABS_f_D passed\n",
      "CT_f_conn_D_An passed\n",
      "CT_f_conn_A_Ca passed\n",
      "CT_n_D_adj_An failed - 48 is not the same as expected 49\n",
      "CT_n_A_adj_Ca failed - 29 is not the same as expected 30\n",
      "Total time to calculate graph: 2.160634994506836 second(s)\n",
      "Total time to calculate descriptors: 0.36923813819885254 second(s)\n",
      "Peak memory usage for graph generation: 4086153 bytes\n",
      "Peak memory usage for descriptor calculation: 29959 bytes\n",
      "{'STAT_n': 3780, 'STAT_e': 596, 'STAT_n_D': 2035, 'STAT_n_A': 1745, 'STAT_CC_D': 7, 'STAT_CC_A': 1, 'STAT_CC_D_An': 3, 'STAT_CC_A_Ca': 1, 'ABS_f_D': 0.53836, 'CT_f_conn_D_An': 0.287961, 'CT_f_conn_A_Ca': 1.0, 'CT_n_D_adj_An': 48, 'CT_n_A_adj_Ca': 29, 'time': 0.36923813819885254, 'mem': 29959}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import igraph_testing_main as ig\n",
    "import importlib\n",
    "import descriptors as ds\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tracemalloc\n",
    "\n",
    "importlib.reload(ig)  \n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_path = f\"{current_dir}/graspi_igraph/data/\"\n",
    "descriptors_path = f\"{current_dir}/graspi_igraph/p1descriptors/\"\n",
    "test_files = [os.path.splitext(file)[0] for file in os.listdir(data_path)]\n",
    "epsilon=1e-5\n",
    "\n",
    "times = []\n",
    "mems = []\n",
    "time_mem_stats = {}\n",
    "\n",
    "targetFileName = '0.25'\n",
    "\n",
    "\n",
    "for test_file in test_files:\n",
    "    if targetFileName not in test_file:\n",
    "        continue\n",
    "\n",
    "    import time\n",
    "    total_graph_time = 0\n",
    "    for i in range(loop_cnt):\n",
    "\n",
    "        # g = ig.generateGraph(data_path + test_file + \".txt\")\n",
    "        tracemalloc.start()\n",
    "        graph_start = time.time()\n",
    "        g,is_2D, black_vertices, white_vertices, black_green, black_interface_red, white_interface_blue, dim, interface_edge_comp_paths, shortest_path_to_red, shortest_path_to_blue, CT_n_D_adj_An, CT_n_A_adj_Ca= ig.generateGraph(data_path + test_file + \".txt\")\n",
    "        _stats = tracemalloc.get_traced_memory()\n",
    "        graph_end = time.time()     \n",
    "        tracemalloc.stop()\n",
    "        graph_mem = _stats[1]-_stats[0]  \n",
    "        stats = ds.desciptors(g)\n",
    "        total_graph_time += graph_end - graph_start\n",
    "        #ig.visual2D(g, 'graph')\n",
    "\n",
    "    print(f\"{test_file} Results\")\n",
    "    with open(descriptors_path + \"p1descriptors.\" + test_file + \".log\") as f:\n",
    "        for line in f:\n",
    "            stat = line.strip().split(\" \")\n",
    "            try:\n",
    "                # if stats.get(stat[0], -1) == int(stat[1]):\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != int(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "            except ValueError:\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != float(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "\n",
    "    descriptor_time = stats[\"time\"]\n",
    "    descriptor_mem = stats[\"mem\"]\n",
    "\n",
    "    times.append(descriptor_time)\n",
    "    mems.append(descriptor_mem)\n",
    "\n",
    "    graph_time = total_graph_time/loop_cnt\n",
    "    print(f\"Total time to calculate graph: {graph_time} second(s)\")\n",
    "    print(f\"Total time to calculate descriptors: {descriptor_time} second(s)\")\n",
    "    print(f\"Peak memory usage for graph generation: {graph_mem} bytes\")\n",
    "    print(f\"Peak memory usage for descriptor calculation: {descriptor_mem} bytes\")\n",
    "    print(stats)\n",
    "    print(\"\")\n",
    "    time_mem_stats[test_file] = {\"graph_time\": graph_time, \"descriptor_time\": descriptor_time,  \"graph_mem\":graph_mem, \"descriptor_mem\": descriptor_mem}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- data_4x3x2 ---\n",
      "\n",
      "[Descriptor Comparison]\n",
      "ABS_f_D: OK -> new : 0.5, prev: 0.5\n",
      "CT_f_conn_A_Ca: OK -> new : 1.0, prev: 1.0\n",
      "CT_f_conn_D_An: OK -> new : 1.0, prev: 1.0\n",
      "CT_n_A_adj_Ca: OK -> new : 6, prev: 6\n",
      "CT_n_D_adj_An: OK -> new : 6, prev: 6\n",
      "STAT_CC_A: OK -> new : 1, prev: 1\n",
      "STAT_CC_A_Ca: OK -> new : 1, prev: 1\n",
      "STAT_CC_D: OK -> new : 1, prev: 1\n",
      "STAT_CC_D_An: OK -> new : 1, prev: 1\n",
      "STAT_e: OK -> new : 12, prev: 12\n",
      "STAT_n: OK -> new : 24, prev: 24\n",
      "STAT_n_A: OK -> new : 12, prev: 12\n",
      "STAT_n_D: OK -> new : 12, prev: 12\n",
      "mem: OK -> new : 389, prev: 389\n",
      "time: DIFFERENT -> new: 0.004912853240966797, prev: 0.004218101501464844\n",
      "\n",
      "[Performance Comparison]\n",
      "Graph Generation Time - new: 0.021146s, prev: 0.020020s\n",
      "Graph Memory Usage     - new: 31517 bytes, prev: 26332 bytes\n",
      "Descriptor Time        - new: 0.004913s, prev: 0.004218s\n",
      "Descriptor Memory      - new: 389 bytes, prev: 389 bytes\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
