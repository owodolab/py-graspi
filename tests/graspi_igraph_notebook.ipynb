{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import graspi_igraph\n",
    "\n",
    "Ensure that you are only using python versions higher than 3.7\n",
    "- Python version can be checked by running *python --version* in the terminal\n",
    "- it can also be checked on notebook via *!pip --version* in the code section of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "# function that makes csv file of dictionary \n",
    "###########################################################################################\n",
    "import csv\n",
    "\n",
    "def save_dict_to_csv(data_dict, file_name):\n",
    "    \"\"\"\n",
    "    Saves a given dictionary as a CSV file.\n",
    "    :param data_dict: Dictionary to be saved (keys are filenames, values are nested dictionaries with data)\n",
    "    :param file_name: Name of the CSV file to be saved (e.g., 'output.csv')\n",
    "    \"\"\"\n",
    "    # Extract headers from the first key\n",
    "    headers = [\"Test File\"]  # First column is the file name\n",
    "    if data_dict:\n",
    "        sample_key = next(iter(data_dict))\n",
    "        headers.extend(data_dict[sample_key].keys())\n",
    "    \n",
    "    # Write to CSV file\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers\n",
    "        \n",
    "        for key, values in data_dict.items():\n",
    "            row = [key] + [values.get(h, None) for h in headers[1:]]\n",
    "            writer.writerow(row)  # Write data rows\n",
    "    \n",
    "    print(f\"CSV file '{file_name}' has been successfully saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization function call\n",
    "---\n",
    "change the file name if you want to visualize other result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "import testing_helper as tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing Code\n",
    "---\n",
    "Doing different igraph file test & generating CSV file(for comparing performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing :: hwi_igraph_testing_main.py (modified green vertex connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_0.5_2.2_001900 Results\n",
      "STAT_n passed\n",
      "STAT_e passed\n",
      "STAT_n_D passed\n",
      "STAT_n_A passed\n",
      "STAT_CC_D passed\n",
      "STAT_CC_A passed\n",
      "STAT_CC_D_An passed\n",
      "STAT_CC_A_Ca passed\n",
      "ABS_wf_D failed - 0.3209214522690966 is not the same as expected 0.308388\n",
      "ABS_f_D passed\n",
      "DISS_wf10_D failed - 0.2166226885998765 is not the same as expected 0.219256\n",
      "DISS_f10_D failed - 0.4269250756579953 is not the same as expected 0.428209\n",
      "CT_f_e_conn passed\n",
      "CT_f_conn_D_An passed\n",
      "CT_f_conn_A_Ca passed\n",
      "CT_e_conn passed\n",
      "CT_e_D_An failed - 1277 is not the same as expected 1278\n",
      "CT_e_A_Ca failed - 1636 is not the same as expected 1638\n",
      "CT_f_D_tort1 failed - 0.32920018265481754 is not the same as expected 0.969159\n",
      "CT_f_A_tort1 failed - 0.2052828809066813 is not the same as expected 0.734028\n",
      "Total time to calculate graph: 31.284925937652588 second(s)\n",
      "Total time to calculate descriptors: 14.678931951522827 second(s)\n",
      "Peak memory usage for graph generation: 79780258 bytes\n",
      "Peak memory usage for descriptor calculation: 0 bytes\n",
      "{'STAT_n': 65536, 'STAT_e': 1634, 'STAT_n_D': 32713, 'STAT_n_A': 32823, 'STAT_CC_D': 2, 'STAT_CC_A': 1, 'STAT_CC_D_An': 1, 'STAT_CC_A_Ca': 1, 'ABS_wf_D': 0.3209214522690966, 'ABS_f_D': 0.4991607666015625, 'DISS_f10_D': 0.4269250756579953, 'DISS_wf10_D': 0.2166226885998765, 'CT_f_e_conn': 0.7821297429620563, 'CT_f_conn_D_An': 0.8702656436279155, 'CT_f_conn_A_Ca': 1.0, 'CT_e_conn': 1278, 'CT_e_D_An': 1277, 'CT_e_A_Ca': 1636, 'CT_n_D_adj_An': 512, 'CT_n_A_adj_Ca': 512, 'CT_f_D_tort1': 0.32920018265481754, 'CT_f_A_tort1': 0.2052828809066813}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import src.graph as ig\n",
    "import src.descriptors as ds\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tracemalloc\n",
    "import src.graph_data_class as gc\n",
    "import importlib\n",
    "\n",
    "importlib.reload(ig)  # 강제 리로드\n",
    "importlib.reload(ds)  # 강제 리로드\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_path = f\"./data/\"\n",
    "descriptors_path = f\"../data/descriptors/\"\n",
    "result_path = f\"./results/\"\n",
    "test_files = [os.path.splitext(file)[0] for file in os.listdir(data_path)]\n",
    "epsilon=1e-5\n",
    "\n",
    "times = []\n",
    "mems = []\n",
    "time_mem_stats = {}\n",
    "\n",
    "for test_file in test_files:\n",
    "    # g = ig.generateGraph(data_path + test_file + \".txt\")\n",
    "    # test_file = \"data_0.5_2.2_001900.txt\"\n",
    "    import time\n",
    "    tracemalloc.start()\n",
    "    graph_start = time.time()\n",
    "    # g,is_2D, black_vertices, white_vertices, black_green, black_interface_red, white_interface_blue, dim, interface_edge_comp_paths, shortest_path_to_red, shortest_path_to_blue, CT_n_D_adj_An, CT_n_A_adj_Ca= ig.generateGraph(test_file)\n",
    "    g_data = ig.generateGraph(data_path+test_file+\".txt\")\n",
    "    # g_data = gc.graph_data_class(g_data.graph, is_2D)\n",
    "    # g_data.black_vertices = black_vertices\n",
    "    # g_data.white_vertices = white_vertices\n",
    "    \n",
    "    mem_graph = tracemalloc.get_traced_memory()\n",
    "    graph_end = time.time()\n",
    "    tracemalloc.stop()\n",
    "    graph_mem = mem_graph[1]-mem_graph[0]  \n",
    "    \n",
    "    desc_start = time.time()\n",
    "    tracemalloc.start()\n",
    "    stats = ds.descriptors(g_data, test_file+\".txt\")\n",
    "    tracemalloc.stop()\n",
    "    desc_end = time.time()\n",
    "    descriptor_time = desc_end - desc_start\n",
    "    mem_desc = tracemalloc.get_traced_memory()\n",
    "    descriptor_mem = mem_desc[1]-mem_desc[0]\n",
    "    #ig.visual2D(g, 'graph')\n",
    "\n",
    "    print(f\"{test_file} Results\")\n",
    "\n",
    "    with open(descriptors_path + \"descriptors.\" + test_file + \".log\") as f:\n",
    "        for line in f:\n",
    "            stat = line.strip().split(\" \")\n",
    "            try:\n",
    "                # if stats.get(stat[0], -1) == int(stat[1]):\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != int(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "            except ValueError:\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != float(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "\n",
    "    times.append(descriptor_time)\n",
    "    mems.append(descriptor_mem)\n",
    "\n",
    "    graph_time = graph_end-graph_start\n",
    "    print(f\"Total time to calculate graph: {graph_time} second(s)\")\n",
    "    print(f\"Total time to calculate descriptors: {descriptor_time} second(s)\")\n",
    "    print(f\"Peak memory usage for graph generation: {graph_mem} bytes\")\n",
    "    print(f\"Peak memory usage for descriptor calculation: {descriptor_mem} bytes\")\n",
    "    print(stats)\n",
    "    print(\"\")\n",
    "    time_mem_stats[test_file] = {\"graph_time\": graph_time, \"descriptor_time\": descriptor_time,  \"graph_mem\":graph_mem, \"descriptor_mem\": descriptor_mem}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change file name \n",
    "save_dict_to_csv(time_mem_stats, \"performance/stats_new_green_method.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
