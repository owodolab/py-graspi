{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import graspi_igraph\n",
    "\n",
    "Ensure that you are only using python versions higher than 3.7\n",
    "- Python version can be checked by running *python --version* in the terminal\n",
    "- it can also be checked on notebook via *!pip --version* in the code section of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "# function that makes csv file of dictionary \n",
    "###########################################################################################\n",
    "import csv\n",
    "\n",
    "def save_dict_to_csv(data_dict, file_name):\n",
    "    \"\"\"\n",
    "    Saves a given dictionary as a CSV file.\n",
    "    :param data_dict: Dictionary to be saved (keys are filenames, values are nested dictionaries with data)\n",
    "    :param file_name: Name of the CSV file to be saved (e.g., 'output.csv')\n",
    "    \"\"\"\n",
    "    # Extract headers from the first key\n",
    "    headers = [\"Test File\"]  # First column is the file name\n",
    "    if data_dict:\n",
    "        sample_key = next(iter(data_dict))\n",
    "        headers.extend(data_dict[sample_key].keys())\n",
    "    \n",
    "    # Write to CSV file\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers\n",
    "        \n",
    "        for key, values in data_dict.items():\n",
    "            row = [key] + [values.get(h, None) for h in headers[1:]]\n",
    "            writer.writerow(row)  # Write data rows\n",
    "    \n",
    "    print(f\"CSV file '{file_name}' has been successfully saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization function call\n",
    "---\n",
    "change the file name if you want to visualize other result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hwi/Develop/ClassSrc/CSE302/py-graspi/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import testing_helper as tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing Code\n",
    "---\n",
    "Doing different igraph file test & generating CSV file(for comparing performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing :: hwi_igraph_testing_main.py (modified green vertex connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testFile-100-2D Results\n",
      "STAT_n passed\n",
      "STAT_e passed\n",
      "STAT_n_D passed\n",
      "STAT_n_A passed\n",
      "STAT_CC_D passed\n",
      "STAT_CC_A passed\n",
      "STAT_CC_D_An passed\n",
      "STAT_CC_A_Ca passed\n",
      "ABS_f_D passed\n",
      "CT_f_conn_D_An passed\n",
      "CT_f_conn_A_Ca passed\n",
      "CT_n_D_adj_An failed - 0 is not the same as expected 1\n",
      "CT_n_A_adj_Ca failed - 0 is not the same as expected 1\n",
      "Total time to calculate graph: 4.242259979248047 second(s)\n",
      "Total time to calculate descriptors: 1.01900315284729 second(s)\n",
      "Peak memory usage for graph generation: 11529357 bytes\n",
      "Peak memory usage for descriptor calculation: 79719 bytes\n",
      "{'STAT_n': 10000, 'STAT_e': 100, 'STAT_n_D': 5000, 'STAT_n_A': 5000, 'STAT_CC_D': 1, 'STAT_CC_A': 1, 'STAT_CC_D_An': 0, 'STAT_CC_A_Ca': 0, 'ABS_f_D': 0.5, 'CT_f_conn_D_An': 0.0, 'CT_f_conn_A_Ca': 0.0, 'CT_n_D_adj_An': 0, 'CT_n_A_adj_Ca': 0, 'time': 1.01900315284729, 'mem': 79719}\n",
      "\n",
      "data_0.528_3.8_000160 Results\n",
      "STAT_n passed\n",
      "STAT_e passed\n",
      "STAT_n_D passed\n",
      "STAT_n_A passed\n",
      "STAT_CC_D passed\n",
      "STAT_CC_A passed\n",
      "STAT_CC_D_An passed\n",
      "STAT_CC_A_Ca passed\n",
      "ABS_f_D passed\n",
      "CT_f_conn_D_An passed\n",
      "CT_f_conn_A_Ca passed\n",
      "CT_n_D_adj_An passed\n",
      "CT_n_A_adj_Ca passed\n",
      "Total time to calculate graph: 18.567856073379517 second(s)\n",
      "Total time to calculate descriptors: 4.467433929443359 second(s)\n",
      "Peak memory usage for graph generation: 47447222 bytes\n",
      "Peak memory usage for descriptor calculation: 323613 bytes\n",
      "{'STAT_n': 40501, 'STAT_e': 3698, 'STAT_n_D': 19268, 'STAT_n_A': 21233, 'STAT_CC_D': 22, 'STAT_CC_A': 5, 'STAT_CC_D_An': 9, 'STAT_CC_A_Ca': 3, 'ABS_f_D': 0.475741, 'CT_f_conn_D_An': 0.319545, 'CT_f_conn_A_Ca': 0.979843, 'CT_n_D_adj_An': 206, 'CT_n_A_adj_Ca': 195, 'time': 4.467433929443359, 'mem': 323613}\n",
      "\n",
      "morphology_resize_0.25x Results\n",
      "STAT_n passed\n",
      "STAT_e passed\n",
      "STAT_n_D passed\n",
      "STAT_n_A passed\n",
      "STAT_CC_D passed\n",
      "STAT_CC_A passed\n",
      "STAT_CC_D_An passed\n",
      "STAT_CC_A_Ca passed\n",
      "ABS_f_D passed\n",
      "CT_f_conn_D_An passed\n",
      "CT_f_conn_A_Ca passed\n",
      "CT_n_D_adj_An failed - 48 is not the same as expected 49\n",
      "CT_n_A_adj_Ca failed - 29 is not the same as expected 30\n",
      "Total time to calculate graph: 1.5789010524749756 second(s)\n",
      "Total time to calculate descriptors: 0.4194350242614746 second(s)\n",
      "Peak memory usage for graph generation: 4238800 bytes\n",
      "Peak memory usage for descriptor calculation: 29674 bytes\n",
      "{'STAT_n': 3780, 'STAT_e': 613, 'STAT_n_D': 2035, 'STAT_n_A': 1745, 'STAT_CC_D': 7, 'STAT_CC_A': 1, 'STAT_CC_D_An': 3, 'STAT_CC_A_Ca': 1, 'ABS_f_D': 0.53836, 'CT_f_conn_D_An': 0.287961, 'CT_f_conn_A_Ca': 1.0, 'CT_n_D_adj_An': 48, 'CT_n_A_adj_Ca': 29, 'time': 0.4194350242614746, 'mem': 29674}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import src.graph as ig\n",
    "import src.descriptors as ds\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tracemalloc\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(ig)  # 강제 리로드\n",
    "importlib.reload(ds)  # 강제 리로드\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_path = f\"../notebook/3d_2d_tests/graspi_igraph/data/\"\n",
    "descriptors_path = f\"../notebook/3d_2d_tests/graspi_igraph/p1descriptors/\"\n",
    "test_files = [os.path.splitext(file)[0] for file in os.listdir(data_path)]\n",
    "epsilon=1e-5\n",
    "\n",
    "times = []\n",
    "mems = []\n",
    "time_mem_stats = {}\n",
    "\n",
    "for test_file in test_files:\n",
    "    # g = ig.generateGraph(data_path + test_file + \".txt\")\n",
    "    import time\n",
    "    tracemalloc.start()\n",
    "    graph_start = time.time()\n",
    "    g,is_2D, black_vertices, white_vertices, black_green, black_interface_red, white_interface_blue, dim, interface_edge_comp_paths, shortest_path_to_red, shortest_path_to_blue, CT_n_D_adj_An, CT_n_A_adj_Ca= ig.generateGraph(data_path + test_file + \".txt\")\n",
    "    _stats = tracemalloc.get_traced_memory()\n",
    "    graph_end = time.time()\n",
    "    tracemalloc.stop()\n",
    "    graph_mem = _stats[1]-_stats[0]  \n",
    "    stats = ds.desciptors(g)\n",
    "    #ig.visual2D(g, 'graph')\n",
    "\n",
    "    print(f\"{test_file} Results\")\n",
    "\n",
    "    with open(descriptors_path + \"p1descriptors.\" + test_file + \".log\") as f:\n",
    "        for line in f:\n",
    "            stat = line.strip().split(\" \")\n",
    "            try:\n",
    "                # if stats.get(stat[0], -1) == int(stat[1]):\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != int(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "            except ValueError:\n",
    "                if abs(stats.get(stat[0], -1) - float(stat[1])) < epsilon:\n",
    "                    print(f\"{stat[0]} passed\")\n",
    "                elif stats.get(stat[0], -1) != -1 and stats.get(stat[0], -1) != float(stat[1]):\n",
    "                    print(f\"{stat[0]} failed - {stats.get(stat[0])} is not the same as expected {stat[1]}\")\n",
    "    descriptor_time = stats[\"time\"]\n",
    "    descriptor_mem = stats[\"mem\"]\n",
    "\n",
    "    times.append(descriptor_time)\n",
    "    mems.append(descriptor_mem)\n",
    "\n",
    "    graph_time = graph_end-graph_start\n",
    "    print(f\"Total time to calculate graph: {graph_time} second(s)\")\n",
    "    print(f\"Total time to calculate descriptors: {descriptor_time} second(s)\")\n",
    "    print(f\"Peak memory usage for graph generation: {graph_mem} bytes\")\n",
    "    print(f\"Peak memory usage for descriptor calculation: {descriptor_mem} bytes\")\n",
    "    print(stats)\n",
    "    print(\"\")\n",
    "    time_mem_stats[test_file] = {\"graph_time\": graph_time, \"descriptor_time\": descriptor_time,  \"graph_mem\":graph_mem, \"descriptor_mem\": descriptor_mem}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change file name \n",
    "save_dict_to_csv(time_mem_stats, \"performance/stats_new_green_method.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
